{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af578fd1-7086-4f5a-ba12-7c269346327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from itertools import product\n",
    "from sklearn.metrics import roc_auc_score, roc_curve,  classification_report, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97952c-6d0a-4e47-88c1-9f60cdbe53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Load Dataset ###\n",
    "Df = pd.read_excel(\"Input the path of Internal Dataset\")\n",
    "\n",
    "X1=Df.iloc[:,0:-1]\n",
    "Y=Df.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e427398-2fd7-4fd8-b6de-f6399c35f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters Grid #####\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 3, 10, 20],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"]  \n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c2353-255b-4438-850e-8751f13d7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X1)\n",
    "y = np.array(Y)\n",
    "\n",
    "## roc-auc score\n",
    "ROC_AUC = []\n",
    "## sensitivity score\n",
    "SEN = []\n",
    "## specificity score\n",
    "SPE = [] \n",
    "## Weighted F1-score\n",
    "F1 = [] \n",
    "## Weighted Precision score\n",
    "Pr=[]\n",
    "## Weighted Recall score\n",
    "Rew=[]\n",
    "\n",
    "outer_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(outer_skf.split(X, y), 1):\n",
    "        \n",
    "    X_train_outer1, X_test1 = X[train_idx], X[test_idx]\n",
    "    y_train_outer, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    ### Nornalization ###\n",
    "    scaler=StandardScaler().fit(X_train_outer1)\n",
    "    X_train_outer=scaler.transform(X_train_outer1)\n",
    "    X_test=scaler.transform(X_test1)\n",
    "\n",
    "    #######################################################################\n",
    "    ### Inner CV (75% of data) for hyperparameter tuning ###\n",
    "    inner_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_inner_auc = 0\n",
    "    best_inner_params = None\n",
    "\n",
    "    for params_candidate in grid:\n",
    "        inner_fold_aucs = []\n",
    "\n",
    "        for inner_train_idx, inner_val_idx in inner_skf.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[inner_train_idx], X_train_outer[inner_val_idx]\n",
    "            y_train_inner, y_val_inner = y_train_outer[inner_train_idx], y_train_outer[inner_val_idx]\n",
    "\n",
    "            ### Class Weight ###\n",
    "            pos = np.sum(y_train_inner == 1)\n",
    "            neg = np.sum(y_train_inner == 0)\n",
    "            scale_pos_weight = neg / pos\n",
    "            \n",
    "            model_inner = SVC(\n",
    "                C=params_candidate[\"C\"],\n",
    "                kernel=params_candidate[\"kernel\"],\n",
    "                gamma=params_candidate[\"gamma\"] if params_candidate[\"kernel\"] == \"rbf\" else \"scale\",\n",
    "                class_weight={0: 1, 1: scale_pos_weight},\n",
    "                probability=True,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            model_inner.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred_prob = model_inner.predict_proba(X_val_inner)[:, 1]\n",
    "            auc = roc_auc_score(y_val_inner, y_val_pred_prob)\n",
    "            inner_fold_aucs.append(auc)\n",
    "\n",
    "        mean_inner_auc = np.mean(inner_fold_aucs)\n",
    "\n",
    "        if mean_inner_auc > best_inner_auc:\n",
    "            best_inner_auc = mean_inner_auc\n",
    "            best_inner_params = params_candidate\n",
    "    #######################################################################\n",
    "\n",
    "    #######################################################################\n",
    "    ### Model performance with the tunned hyperparameters ###\n",
    "    ## Class weight ##\n",
    "    pos = np.sum(y_train_outer == 1)\n",
    "    neg = np.sum(y_train_outer == 0)\n",
    "    scale_pos_weight = neg / pos\n",
    "\n",
    "    model_outer = SVC(\n",
    "        C=best_inner_params[\"C\"],\n",
    "        kernel=best_inner_params[\"kernel\"],\n",
    "        gamma=best_inner_params[\"gamma\"] if best_inner_params[\"kernel\"] == \"rbf\" else \"scale\",\n",
    "        class_weight={0: 1, 1: scale_pos_weight},\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    ) \n",
    "    y_test_pred = final_model.predict(dtest_outer)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred_optimal = (y_test_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    ## Performance metrics evaluation \n",
    "    report = classification_report(y_test, y_pred_optimal, output_dict=True)\n",
    "    print(classification_report(y_test, y_pred_optimal))\n",
    "    auc = roc_auc_score(y_test, y_pred_optimal)\n",
    "    Sensitivity=report['1']['recall']\n",
    "    Specificity=report['0']['recall']\n",
    "    F1score=report['weighted avg']['f1-score']\n",
    "    Recall_w=report['weighted avg']['recall']\n",
    "    Precision=report['weighted avg']['precision']\n",
    "  \n",
    "    ROC_AUC.append(auc)\n",
    "    SEN.append(Sensitivity)\n",
    "    SPE.append(Specificity)\n",
    "    F1.append(F1score)\n",
    "    Pr.append(Precision)\n",
    "    Rew.append(Recall_w) \n",
    "\n",
    "\n",
    "print(np.mean(ROC_AUC), np.mean(SEN), np.mean(SPE), np.mean(F1), np.mean(Pr), np.mean(Rew))\n",
    "print(np.std(ROC_AUC), np.std(SEN), np.std(SPE), np.std(F1), np.std(Pr), np.std(Rew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b23c7-d586-4591-b105-bbf0ef6bcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_ROC_AUC = np.percentile(ROC_AUC, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_ROC_AUC}\")\n",
    "\n",
    "confidence_interval_SEN = np.percentile(SEN, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_SEN}\")\n",
    "\n",
    "confidence_interval_SPE = np.percentile(SPE, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_SPE}\")\n",
    "\n",
    "confidence_interval_F1 = np.percentile(F1, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_F1}\")\n",
    "\n",
    "confidence_interval_Pr = np.percentile(Pr, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_Pr}\")\n",
    "\n",
    "confidence_interval_Rew = np.percentile(Rew, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_Rew}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
