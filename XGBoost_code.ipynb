{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af578fd1-7086-4f5a-ba12-7c269346327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from itertools import product\n",
    "from sklearn.metrics import roc_auc_score, roc_curve,  classification_report, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64ce0a-5b3f-4f77-baba-f02cfa14fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_obj(alpha=0.25, gamma=2.0):\n",
    "    def fl_obj(preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "        preds = np.clip(preds, 1e-9, 1 - 1e-9)\n",
    "        grad = (\n",
    "            alpha * labels * (1 - preds) ** gamma * (gamma * preds * np.log(preds) + preds - 1) +\n",
    "            (1 - alpha) * (1 - labels) * preds ** gamma * (gamma * (1 - preds) * np.log(1 - preds) - preds)\n",
    "        )\n",
    "        hess = (\n",
    "            alpha * labels * (1 - preds) ** gamma * preds * (1 - preds) +\n",
    "            (1 - alpha) * (1 - labels) * preds ** gamma * preds * (1 - preds)\n",
    "        )\n",
    "        return grad, hess\n",
    "    return fl_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97952c-6d0a-4e47-88c1-9f60cdbe53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Load Dataset ###\n",
    "Df = pd.read_excel(\"Input the path of Internal Dataset\")\n",
    "\n",
    "X1=Df.iloc[:,0:-1]\n",
    "Y=Df.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e427398-2fd7-4fd8-b6de-f6399c35f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters Grid #####\n",
    "param_grid = {\n",
    "    \"max_depth\": [10, 20, 30, 40, 50],\n",
    "    \"eta\": [0.001, 0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.8, 0.9],\n",
    "    \"alpha\": [0.25, 0.5],\n",
    "    \"gamma\": [1.0, 2.0]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c2353-255b-4438-850e-8751f13d7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X1)\n",
    "y = np.array(Y)\n",
    "\n",
    "## roc-auc score\n",
    "ROC_AUC = []\n",
    "## sensitivity score\n",
    "SEN = []\n",
    "## specificity score\n",
    "SPE = [] \n",
    "## Weighted F1-score\n",
    "F1 = [] \n",
    "## Weighted Precision score\n",
    "Pr=[]\n",
    "## Weighted Recall score\n",
    "Rew=[]\n",
    "\n",
    "outer_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "outer_auc_scores = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(outer_skf.split(X, y), 1):\n",
    "    print(f\"Outer Fold {fold_num}\")\n",
    "    \n",
    "    X_train_outer1, X_test1 = X[train_idx], X[test_idx]\n",
    "    y_train_outer, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    ### Nornalization ###\n",
    "    scaler=StandardScaler().fit(X_train_outer1)\n",
    "    X_train_outer=scaler.transform(X_train_outer1)\n",
    "    X_test=scaler.transform(X_test1)\n",
    "\n",
    "    #######################################################################\n",
    "    ### Inner CV (75% of data) for hyperparameter tuning ###\n",
    "    inner_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_inner_auc = 0\n",
    "    best_inner_params = None\n",
    "\n",
    "    for params_candidate in grid:\n",
    "        inner_fold_aucs = []\n",
    "\n",
    "        for inner_train_idx, inner_val_idx in inner_skf.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[inner_train_idx], X_train_outer[inner_val_idx]\n",
    "            y_train_inner, y_val_inner = y_train_outer[inner_train_idx], y_train_outer[inner_val_idx]\n",
    "\n",
    "            ### Class Weight ###\n",
    "            pos = np.sum(y_train_inner == 1)\n",
    "            neg = np.sum(y_train_inner == 0)\n",
    "            scale_pos_weight = neg / pos\n",
    "\n",
    "            dtrain_inner = xgb.DMatrix(X_train_inner, label=y_train_inner)\n",
    "            dval_inner = xgb.DMatrix(X_val_inner, label=y_val_inner)\n",
    "\n",
    "            model_inner = xgb.train(\n",
    "                params={\n",
    "                    \"max_depth\": params_candidate[\"max_depth\"],\n",
    "                    \"eta\": params_candidate[\"eta\"],\n",
    "                    \"subsample\": params_candidate[\"subsample\"],\n",
    "                    \"colsample_bytree\": params_candidate[\"colsample_bytree\"],\n",
    "                    \"eval_metric\": \"auc\",\n",
    "                    \"scale_pos_weight\": scale_pos_weight\n",
    "                },\n",
    "                dtrain=dtrain_inner,\n",
    "                num_boost_round=1000,\n",
    "                obj=focal_loss_obj(alpha=params_candidate[\"alpha\"], gamma=params_candidate[\"gamma\"]),\n",
    "                evals=[(dval_inner, \"validation\")],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "\n",
    "            y_val_pred = model_inner.predict(dval_inner)\n",
    "            auc = roc_auc_score(y_val_inner, y_val_pred)\n",
    "            inner_fold_aucs.append(auc)\n",
    "\n",
    "        mean_inner_auc = np.mean(inner_fold_aucs)\n",
    "\n",
    "        if mean_inner_auc > best_inner_auc:\n",
    "            best_inner_auc = mean_inner_auc\n",
    "            best_inner_params = params_candidate\n",
    "    #######################################################################\n",
    "\n",
    "    #######################################################################\n",
    "    ### Model performance with the tunned hyperparameters ###\n",
    "    ## Class weight ##\n",
    "    pos = np.sum(y_train_outer == 1)\n",
    "    neg = np.sum(y_train_outer == 0)\n",
    "    scale_pos_weight = neg / pos\n",
    "\n",
    "    dtrain_outer = xgb.DMatrix(X_train_outer, label=y_train_outer)\n",
    "    dtest_outer = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    final_model = xgb.train(\n",
    "        params={\n",
    "            \"max_depth\": best_inner_params[\"max_depth\"],\n",
    "            \"eta\": best_inner_params[\"eta\"],\n",
    "            \"subsample\": best_inner_params[\"subsample\"],\n",
    "            \"colsample_bytree\": best_inner_params[\"colsample_bytree\"],\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"scale_pos_weight\": scale_pos_weight\n",
    "        },\n",
    "        dtrain=dtrain_outer,\n",
    "        num_boost_round=1000,\n",
    "        obj=focal_loss_obj(alpha=best_inner_params[\"alpha\"], gamma=best_inner_params[\"gamma\"]),\n",
    "        evals=[(dtest_outer, \"test\")],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    y_test_pred = final_model.predict(dtest_outer)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred_optimal = (y_test_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    ## Performance metrics evaluation \n",
    "    report = classification_report(y_test, y_pred_optimal, output_dict=True)\n",
    "    print(classification_report(y_test, y_pred_optimal))\n",
    "    auc = roc_auc_score(y_test, y_pred_optimal)\n",
    "    Sensitivity=report['1']['recall']\n",
    "    Specificity=report['0']['recall']\n",
    "    F1score=report['weighted avg']['f1-score']\n",
    "    Recall_w=report['weighted avg']['recall']\n",
    "    Precision=report['weighted avg']['precision']\n",
    "  \n",
    "    ROC_AUC.append(auc)\n",
    "    SEN.append(Sensitivity)\n",
    "    SPE.append(Specificity)\n",
    "    F1.append(F1score)\n",
    "    Pr.append(Precision)\n",
    "    Rew.append(Recall_w) \n",
    "\n",
    "\n",
    "print(np.mean(ROC_AUC), np.mean(SEN), np.mean(SPE), np.mean(F1), np.mean(Pr), np.mean(Rew))\n",
    "print(np.std(ROC_AUC), np.std(SEN), np.std(SPE), np.std(F1), np.std(Pr), np.std(Rew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b23c7-d586-4591-b105-bbf0ef6bcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_ROC_AUC = np.percentile(ROC_AUC, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_ROC_AUC}\")\n",
    "\n",
    "confidence_interval_SEN = np.percentile(SEN, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_SEN}\")\n",
    "\n",
    "confidence_interval_SPE = np.percentile(SPE, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_SPE}\")\n",
    "\n",
    "confidence_interval_F1 = np.percentile(F1, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_F1}\")\n",
    "\n",
    "confidence_interval_Pr = np.percentile(Pr, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_Pr}\")\n",
    "\n",
    "confidence_interval_Rew = np.percentile(Rew, [2.5, 97.5])\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval_Rew}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
