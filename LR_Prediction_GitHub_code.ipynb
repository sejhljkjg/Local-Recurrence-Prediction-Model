{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26355e2-93b8-43fc-b6d9-ebfcf9fee9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries #####\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import Loss\n",
    "from keras.saving import register_keras_serializable\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report,\\\n",
    "                            ConfusionMatrixDisplay, recall_score, \\\n",
    "                            f1_score, roc_auc_score, roc_curve, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13628e45-7a78-45fc-b57c-abb21e8b8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Dataset ###\n",
    "\n",
    "## Dataset for cross-validation\n",
    "DF_internal = pd.read_excel(\"Input the path of Internal Dataset\")\n",
    "## Dataset for external validation\n",
    "DF_external = pd.read_excel(\"Input the path of External Dataset\")\n",
    "\n",
    "\n",
    "DF_internal=DF_internal.sample(frac=1, random_state=42)\n",
    "DF_external=DF_external.sample(frac=1, random_state=42)\n",
    "\n",
    "X_internal=DF_internal.iloc[:,0:-1]\n",
    "Y_internal=DF_internal.iloc[:,-1]\n",
    "\n",
    "X_external=DF_external.iloc[:,0:-1]\n",
    "Y_external=DF_external.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea17347-e7fd-4c53-b847-de4d955ba004",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Focal Loss Function ########\n",
    "\n",
    "@register_keras_serializable()\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    @register_keras_serializable()\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, K.floatx())\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912329a9-98ed-447c-adc4-68a7678afb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Architecture of ANN-model for Local Recurrence Prediction ###\n",
    "\n",
    "def ANN_model(input_dimension):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=input_dimension, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(150, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = AdamW(learning_rate=1e-3, weight_decay=1e-4)\n",
    "    model.compile(loss=focal_loss(gamma=2., alpha=0.25), optimizer=opt, metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9afa7-816b-4ca7-8213-dcb1afe32b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stratified Cross-validation\n",
    "\n",
    "def kfold_cv(X, Y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    for train_idx, test_idx in skf.split(X, Y):\n",
    "        Y_test = Y.iloc[test_idx]\n",
    "        if len(np.unique(Y_test)) < 2:\n",
    "            print(\"Skipping fold: only one class\")\n",
    "            continue\n",
    "        yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3765b-73e2-45d3-966d-2b42e759a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main execution ###\n",
    "\n",
    "best_score = -np.inf\n",
    "best_model = None\n",
    "auc_scores_train, auc_scores_test = [], []\n",
    "\n",
    "### Nornalization ###\n",
    "scaler=StandardScaler().fit(X_internal)\n",
    "X=scaler.transform(X_internal)\n",
    "X_external_v=scaler.transform(X_external)\n",
    "\n",
    "Y=Y_internal\n",
    "Y_external_v=Y_internal\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold_cv(X, Y, n_splits=5), 1):\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    model = ANN_model(X_train.shape[1])\n",
    "       \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=20, verbose=1, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=20, restore_best_weights=True, mode='min')\n",
    "    model_checkpoint = ModelCheckpoint(\"best_model.keras\", monitor=\"loss\", save_best_only=True, mode=\"min\")\n",
    "    y_train = np.array(y_train).flatten().astype(int)\n",
    "    classes = np.array([0, 1])\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "    class_weight = dict(zip(classes, weights))\n",
    "    model.fit(X_train, y_train, epochs=200, class_weight=class_weight, callbacks=[reduce_lr, early_stopping, model_checkpoint],verbose=0)  \n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds1 = roc_curve(y_train, y_train_pred)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds1[optimal_idx]\n",
    "\n",
    "    ### Output for training phase ###\n",
    "    y_train_pred_optimal = (y_train_pred >= optimal_threshold).astype(int)\n",
    "    ### Output for testing phase ###\n",
    "    y_test_pred_optimal = (y_test_pred >= optimal_threshold).astype(int)\n",
    "\n",
    "    ### Performance Evaluation ###\n",
    "    print(classification_report(y_train, y_train_pred_optimal))\n",
    "    print(classification_report(y_test, y_test_pred_optimal))\n",
    "\n",
    "    ### ROC-AUC score ###\n",
    "    roc_auc_train = roc_auc_score(y_train, y_train_pred_optimal)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_test_pred_optimal)\n",
    "\n",
    "    \n",
    "    auc_scores_train.append(roc_auc_train)\n",
    "    auc_scores_test.append(roc_auc_test)\n",
    "    \n",
    "    print(f\"Fold {fold} ROC-AUC: {roc_auc_train:.2f}\")\n",
    "    print(f\"Fold {fold} ROC-AUC: {roc_auc_test:.2f}\")\n",
    "    \n",
    "    ### Save the Best Model ###\n",
    "    if roc_auc_test > best_score:\n",
    "        best_score = roc_auc_test\n",
    "        best_model = model\n",
    "        best_model.save(\"Best_Model.keras\")\n",
    "\n",
    "\n",
    "print(f\"\\nMean ROC AUC over {len(auc_scores_train)} valid folds: {np.mean(auc_scores_train):.4f}\")\n",
    "print(f\"\\nMean ROC AUC over {len(auc_scores_test)} valid folds: {np.mean(auc_scores_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1815148-ba57-4552-8498-59de46c1a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "### External Validation ###\n",
    "\n",
    "## roc-auc score\n",
    "ROC_AUC = []\n",
    "## sensitivity score\n",
    "SEN = []\n",
    "## specificity score\n",
    "SPE = [] \n",
    "## Weighted F1-score\n",
    "F1 = [] \n",
    "## Weighted Precision score\n",
    "Pr=[]\n",
    "## Weighted Recall score\n",
    "Rew=[]\n",
    "\n",
    "X_test2=np.array(X_external_v)\n",
    "Y_test2 = np.array(Y_external_v)\n",
    "samples = 1000 \n",
    "\n",
    "## Load trained model\n",
    "Model = load_model(\"best_model_1.keras\", custom_objects={'focal_loss': focal_loss})\n",
    "\n",
    "\n",
    "for i in range(samples):\n",
    "    indices = np.random.choice(np.arange(X_test2.shape[0]), size=X_test2.shape[0], replace=True)\n",
    "    X_boot, Y_boot = X_test2[indices], Y_test2[indices]\n",
    "    \n",
    "    Y_pred=Model.predict(X_boot)\n",
    "    Y_pred_optimal = (Y_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    ## Performance metrics evaluation \n",
    "    report = classification_report(Y_boot, Y_pred_optimal, output_dict=True)\n",
    "    auc = roc_auc_score(Y_boot, Y_pred_optimal)\n",
    "    Sensitivity=report['1']['recall']\n",
    "    Specificity=report['0']['recall']\n",
    "    F1score=report['weighted avg']['f1-score']\n",
    "    Recall_w=report['weighted avg']['recall']\n",
    "    Precision=report['weighted avg']['precision']\n",
    "  \n",
    "    ROC_AUC.append(auc)\n",
    "    SEN.append(Sensitivity)\n",
    "    SPE.append(Specificity)\n",
    "    F1.append(F1score)\n",
    "    Pr.append(Precision)\n",
    "    Rew.append(Recall_w) \n",
    "\n",
    "confidence_interval = np.percentile(ROC_AUC, [2.5, 97.5])\n",
    "\n",
    "print(np.mean(ROC_AUC), np.mean(SEN), np.mean(SPE), np.mean(F1), np.mean(Pr), np.mean(Rew))\n",
    "print(np.std(ROC_AUC), np.std(SEN), np.std(SPE), np.std(F1), np.std(Pr), np.std(Rew))\n",
    "print(f\"Bootstrap 95% Confidence Interval: {confidence_interval}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
